{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import sklearn.utils, sklearn.preprocessing, sklearn.decomposition, sklearn.svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificacion de Generos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos los data del Data Analysis\n",
    "data = pd.read_pickle(\"clean_data/track.pkl\")\n",
    "clean_features = pd.read_pickle(\"clean_data/features.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las siguientes lineas no deberia copiarse ya que las estan  en la notebook de Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_features = [\"chroma_cens\", \"chroma_cqt\", \"chroma_stft\", \"mfcc\", \"rmse\", \"spectral_bandwidth\", \"spectral_contrast\", \"spectral_rolloff\", \"tonnetz\", \"zcr\"]\n",
    "_fields = [\"kurtosis\", \"mean\", \"std\", \"median\", \"max\", \"min\"]\n",
    "\n",
    "audio_features_df  = clean_features\n",
    "audio_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten features\n",
    "tracks_with_extra_audio_features_df = pd.DataFrame(index=audio_features_df.index)\n",
    "tracks_with_extra_audio_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initializing all needed columns with NaN\n",
    "for index, row in audio_features_df.head(1).iterrows():\n",
    "    print(index) # track id\n",
    "    for feature in _features:\n",
    "        for field in _fields:\n",
    "            i = 0\n",
    "            for k in row[feature][field]: # channel (if it is channel ?)                \n",
    "                i += 1\n",
    "                tracks_with_extra_audio_features_df[f'{feature}_{field[0:3]}_{i}'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in audio_features_df.iterrows():\n",
    "    for feature in _features:\n",
    "        for field in _fields:\n",
    "            i = 0\n",
    "            for k in row[feature][field]: # channel (if it is channel ?)                \n",
    "                i += 1\n",
    "                tracks_with_extra_audio_features_df[f'{feature}_{field[0:3]}_{i}'] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features= tracks_with_extra_audio_features_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias a importar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import offsetbox\n",
    "import joblib\n",
    "#from PIL import Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "#from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import auc, plot_roc_curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generamos la Matriz de features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_numericos=[\"duration\", \"acousticness\",\"album_tracks\", \"danceability\",\"energy\",\"instrumentalness\", \"liveness\",  \"speechiness\",\"tempo\",\"valence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropeo location porque tiene muchos nulos \n",
    "data.drop(labels=[\"location\", \"date_created\",\"title\", \"album\",\"artist\"],axis=1, inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Media de las variables: \")\n",
    "print(data.mean(axis=0))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(\"Varianza de las variables: \")\n",
    "print(data.var(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('genre_top', axis=1)\n",
    "y = data['genre_top']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=7, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(y_train.value_counts(normalize=True).round(2))\n",
    "\n",
    "display(y_test.value_counts(normalize=True).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_genre_fatures_sc = scaler.fit_transform(X_train)\n",
    "X_train_sc_df = pd.DataFrame(train_genre_fatures_sc, columns = features_numericos)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_genre_fatures_sc = scaler.fit_transform(X_test)\n",
    "X_test_sc_df = pd.DataFrame(train_genre_fatures_sc, columns = features_numericos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Media de las variables: \")\n",
    "print(X_train_sc_df.mean(axis=0))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Observamos nuevamente la varianza de las variables: como normalizamos la varianza es 1\n",
    "print(\"Varianza de las variables: \")\n",
    "print(X_train_sc_df.var(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_plot_confusion_matrix(confusion_matrix, genre_list=['Blues', 'Hip-Hop','Jazz', 'Pop', 'Rock']):\n",
    "    df_cm = pd.DataFrame(confusion_matrix, \n",
    "                         index = genre_list, \n",
    "                         columns = genre_list)\n",
    "    plt.figure(figsize = (14,9))\n",
    "    sns.heatmap(df_cm, annot=True, fmt='g', cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Modelo de NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train_sc_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = gnb.predict(X_test_sc_df)\n",
    "\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(accuracy_score(y_test, Y_pred), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy=', accuracy_score(y_test, Y_pred))\n",
    "#print('Recall=', recall_score(Y_test, Y_pred))\n",
    "#print('Precision=', precision_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(y_test, Y_pred), annot=True, fmt='.0f')\n",
    "plt.ylabel('Etiquetas reales')\n",
    "plt.xlabel('Etiquetas predichas');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Modelo de KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la clase KNeighborsClassifier de módulo neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train_sc_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test_sc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "kf = KFold(n_splits=12, shuffle=True, random_state=12)\n",
    "\n",
    "scores_para_df = []\n",
    "\n",
    "for i in range(1, 21):\n",
    "    \n",
    "    # En cada iteración, instanciamos el modelo con un hiperparámetro distinto\n",
    "    model = KNeighborsClassifier(n_neighbors=i)\n",
    "    \n",
    "    # cross_val_scores nos devuelve un array de 5 resultados,\n",
    "    # uno por cada partición que hizo automáticamente CV\n",
    "    cv_scores = cross_val_score(model, X_train_sc_df, y_train, cv=kf)\n",
    "    \n",
    "    # Para cada valor de n_neighbours, creamos un diccionario con el valor\n",
    "    # de n_neighbours y la media y el desvío de los scores\n",
    "    dict_row_score = {'score_medio':np.mean(cv_scores),\n",
    "                      'score_std':np.std(cv_scores), 'n_neighbors':i}\n",
    "    \n",
    "    # Guardamos cada uno en la lista de diccionarios\n",
    "    scores_para_df.append(dict_row_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame(scores_para_df)\n",
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores['limite_inferior'] = df_scores['score_medio'] - df_scores['score_std']\n",
    "df_scores['limite_superior'] = df_scores['score_medio'] + df_scores['score_std']\n",
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados\n",
    "plt.plot(df_scores['n_neighbors'], df_scores['limite_inferior'], color='r')\n",
    "plt.plot(df_scores['n_neighbors'], df_scores['score_medio'], color='b')\n",
    "plt.plot(df_scores['n_neighbors'], df_scores['limite_superior'], color='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificamos el score máximo\n",
    "df_scores.loc[df_scores.score_medio == df_scores.score_medio.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos el valor del k óptimo a una variable\n",
    "best_k = df_scores_standard.loc[df_scores_standard.score_medio == df_scores_standard.score_medio.max(), 'n_neighbors'].values[0]\n",
    "best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegimos el modelo óptimo de acuerdo a las pruebas de cross validation\n",
    "model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "\n",
    "# Lo ajustamos sobre los datos de entrenamiento\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluamos qué accuracy obtenemos en train\n",
    "accuracy_score(Y_train, model.predict(X_train)).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo utilizamos para predecir en test\n",
    "X_test = scaler.transform(X_test) # ¡Importantísimo estandarizar también los datos de test con las medias y desvíos aprendidos en train!\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos el accuracy del modelo en test\n",
    "accuracy_score(Y_test, y_pred).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "sns.set(rc={'figure.figsize':(30,30)})\n",
    "\n",
    "# Graficamos la matriz de confusión\n",
    "print(confusion_matrix(Y_test, y_pred))\n",
    "plot_confusion_matrix(model,X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(Y_test, y_pred), annot=True, fmt='.0f')\n",
    "plt.ylabel('Etiquetas reales')\n",
    "plt.xlabel('Etiquetas predichas');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejoras al modelo con GridSearch & Pipeline KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "folds=StratifiedKFold(n_splits=5,shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasos = [('scaler', StandardScaler()), ('knn', KNeighborsClassifier())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_grid = Pipeline(pasos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'knn__n_neighbors':range(2,20,2),'knn__weights':['uniform','distance']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe_grid, param_grid, cv=folds)\n",
    "grid.fit(X_train_numerical_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(grid.best_estimator_.predict(X_test_numerical_scaled),Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelamos unicamente teniendo encuenta los siguietne generos:\n",
    "'Rock': 1500, 'Pop': 1105, 'Jazz': 440, 'Hip-Hop': 1048, 'Blues': 154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No pude hacer usar la libreria:  imblearn\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "sampler=RandomUnderSampler(sampling_strategy=undersampling_ratio)\n",
    "Xu,yu=sampler.fit_resample(X_train,y_train)\n",
    "\n",
    "yu.value_counts()\n",
    "\n",
    "oversampling_ratio = dict(zip(list(y_train.unique()), [1500, 1500, 1200, 1500, 600]))\n",
    "oversampling_ratio\n",
    "\n",
    "categorical_mask=(X_train.dtypes=='category').values\n",
    "sm=RandomOverSampler(sampling_strategy=oversampling_ratio)\n",
    "X_train_rs,y_train_rs=sm.fit_resample(Xu,yu)\n",
    "\n",
    "print(y_train_rs.shape)\n",
    "print(y_train_rs.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch Stratified KFold - Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "model_instance = RandomForestClassifier()\n",
    "\n",
    "gridSearch_params = {'n_estimators':[100, 500],\n",
    "          'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': [None, 3, 7, 10, 15],\n",
    "          'min_samples_split': [5, 7],\n",
    "          'class_weight':[None, 'balanced']}\n",
    "\n",
    "\n",
    "cv_Stratified_KFold = StratifiedKFold(n_splits=5, shuffle=True, random_state=77)\n",
    "\n",
    "grid_search_CV_Stratified_KFold_model_RF = GridSearchCV(model_instance, gridSearch_params, n_jobs=-1, cv = cv_Stratified_KFold)\n",
    "grid_search_CV_Stratified_KFold_model_RF.fit(X_train_rs, y_train_rs)\n",
    "\n",
    "scores_Stratified_KFold = cross_val_score(model_instance, X_train_rs, y_train_rs, cv=cv_Stratified_KFold, n_jobs=-1)\n",
    "mean_score_grid_search_CV_Stratified_KFold_model = scores_Stratified_KFold.mean()\n",
    "std_score_grid_search_CV_Stratified_KFold_model = scores_Stratified_KFold.std()    \n",
    "\n",
    "#score_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model_RF.best_score_\n",
    "#params_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model_RF.best_params_\n",
    "\n",
    "score_grid_search_CV_Stratified_KFold_model_test = grid_search_CV_Stratified_KFold_model_RF.score(X_test_sc_df, y_test)\n",
    "predictions_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model_RF.predict(X_test_sc_df)\n",
    "confusion_matrix_grid_search_CV_Stratified_KFold_model = metrics.confusion_matrix(y_test, predictions_grid_search_CV_Stratified_KFold_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_plot_confusion_matrix(confusion_matrix(y_test, grid_search_CV_Stratified_KFold_model_RF.predict(X_test_sc_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Para RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRFClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Usando XG Boosting\n",
    "model_instance = XGBRFClassifier(n_estimators=1000, subsample=0.9, colsample_bynode=0.2)\n",
    "\n",
    "gridSearch_params = {'n_estimators':[1000],\n",
    "                     'max_depth': [None, 3, 5]}\n",
    "\n",
    "\n",
    "cv_Stratified_KFold = StratifiedKFold(n_splits=3, shuffle=True, random_state=77)\n",
    "\n",
    "grid_search_CV_Stratified_KFold_model = GridSearchCV(model_instance, gridSearch_params, n_jobs=-1, cv = cv_Stratified_KFold)\n",
    "grid_search_CV_Stratified_KFold_model.fit(X_train_rs, y_train_rs)\n",
    "\n",
    "scores_Stratified_KFold = cross_val_score(model_instance, X_train_rs, y_train_rs, cv=cv_Stratified_KFold, n_jobs=-1)\n",
    "mean_score_grid_search_CV_Stratified_KFold_model = scores_Stratified_KFold.mean()\n",
    "std_score_grid_search_CV_Stratified_KFold_model = scores_Stratified_KFold.std()    \n",
    "\n",
    "score_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model.best_score_\n",
    "params_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model.best_params_\n",
    "\n",
    "score_grid_search_CV_Stratified_KFold_model_test = grid_search_CV_Stratified_KFold_model.score(X_test_sc_df, y_test)\n",
    "predictions_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model.predict(X_test_sc_df)\n",
    "confusion_matrix_grid_search_CV_Stratified_KFold_model = metrics.confusion_matrix(y_test, predictions_grid_search_CV_Stratified_KFold_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_plot_confusion_matrix(confusion_matrix(y_test, grid_search_CV_Stratified_KFold_model.predict(X_test_sc_df)))\n",
    "\n",
    "y_test.value_counts()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid_search_CV_Stratified_KFold_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_score_grid_search_CV_Stratified_KFold_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_score_grid_search_CV_Stratified_KFold_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_grid_search_CV_Stratified_KFold_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_grid_search_CV_Stratified_KFold_model_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## Noisy data makes XG Random Forest Boost to perfom badly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = ['Hip-Hop', 'Pop', 'Blues', 'Jazz']\n",
    "echonest_track_ids = set(list(echonest.index))\n",
    "\n",
    "original_genre_top_selected_genres_ids = ( set(list((tracks_genres_info[tracks_genres_info.genre_top == 'Hip-Hop']).index)) | \n",
    "                                           set(list((tracks_genres_info[tracks_genres_info.genre_top == 'Pop']).index))     |\n",
    "                                           set(list((tracks_genres_info[tracks_genres_info.genre_top == 'Rock']).index))    | \n",
    "                                           set(list((tracks_genres_info[tracks_genres_info.genre_top == 'Blues']).index))   | \n",
    "                                           set(list((tracks_genres_info[tracks_genres_info.genre_top == 'Jazz']).index)))   \n",
    "\n",
    "original_genre_top_selected_genres_ids = original_genre_top_selected_genres_ids &  echonest_track_ids # Only the ones that has Echonest features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original tracks: \", tracks_genres_info[tracks_genres_info.index.isin(original_genre_top_selected_genres_ids)].shape[0])\n",
    "\n",
    "print(tracks_genres_info[tracks_genres_info.index.isin(original_genre_top_selected_genres_ids)].genre_top.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derived_genre_tracks_ids = {} \n",
    "\n",
    "for genre in genres:    \n",
    "    derived_genre_tracks_ids[genre] = set(list(null_top_genre_tracks_df[null_top_genre_tracks_df.derived_genre_top == genre].index)) & (echonest_track_ids)\n",
    "\n",
    "print(\"Derived Genre Tracks:\")\n",
    "for genre, ids in derived_genre_tracks_ids.items():\n",
    "    print(f'\\t{genre}: {len(ids)}')\n",
    "    len(derived_genre_tracks_ids['Pop'])\n",
    "\n",
    "flat_list_derived_genre_track_ids = sorted({x for v in derived_genre_tracks_ids.values() for x in v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_fatures_df = pd.concat([echonest.echonest.audio_features[echonest.index.isin(original_genre_top_selected_genres_ids)], tracks_info_with_derived_top_genre_df[tracks_info_with_derived_top_genre_df._genre_top.index.isin(original_genre_top_selected_genres_ids)]], 1)\n",
    "\n",
    "derived_genre_fatures_df = pd.concat([echonest.echonest.audio_features[echonest.index.isin(flat_list_derived_genre_track_ids)], null_top_genre_tracks_df[null_top_genre_tracks_df.derived_genre_top.index.isin(flat_list_derived_genre_track_ids)]], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_fatures_df\n",
    "\n",
    "derived_genre_fatures_df['genre_top'] = derived_genre_fatures_df.derived_genre_top\n",
    "\n",
    "derived_genre_fatures_df.genre_top.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1501,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X = genre_fatures_df[full_features]\n",
    "y = genre_fatures_df['genre_top']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1505,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36730</th>\n",
       "      <td>0.002562</td>\n",
       "      <td>0.371206</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.938766</td>\n",
       "      <td>0.099965</td>\n",
       "      <td>0.118478</td>\n",
       "      <td>120.170</td>\n",
       "      <td>0.052455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75751</th>\n",
       "      <td>0.175495</td>\n",
       "      <td>0.684260</td>\n",
       "      <td>0.682260</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.126889</td>\n",
       "      <td>0.038587</td>\n",
       "      <td>89.989</td>\n",
       "      <td>0.332568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14184</th>\n",
       "      <td>0.728182</td>\n",
       "      <td>0.489313</td>\n",
       "      <td>0.301333</td>\n",
       "      <td>0.873091</td>\n",
       "      <td>0.161249</td>\n",
       "      <td>0.057750</td>\n",
       "      <td>75.044</td>\n",
       "      <td>0.614381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36746</th>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.338520</td>\n",
       "      <td>0.988323</td>\n",
       "      <td>0.917932</td>\n",
       "      <td>0.069609</td>\n",
       "      <td>0.110313</td>\n",
       "      <td>143.774</td>\n",
       "      <td>0.089863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27607</th>\n",
       "      <td>0.575338</td>\n",
       "      <td>0.844497</td>\n",
       "      <td>0.454838</td>\n",
       "      <td>0.780293</td>\n",
       "      <td>0.076708</td>\n",
       "      <td>0.064396</td>\n",
       "      <td>130.051</td>\n",
       "      <td>0.352131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>0.171406</td>\n",
       "      <td>0.456081</td>\n",
       "      <td>0.680751</td>\n",
       "      <td>0.930712</td>\n",
       "      <td>0.081202</td>\n",
       "      <td>0.028629</td>\n",
       "      <td>107.080</td>\n",
       "      <td>0.496760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21521</th>\n",
       "      <td>0.179581</td>\n",
       "      <td>0.564068</td>\n",
       "      <td>0.743802</td>\n",
       "      <td>0.634654</td>\n",
       "      <td>0.117850</td>\n",
       "      <td>0.036937</td>\n",
       "      <td>128.056</td>\n",
       "      <td>0.813390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4108</th>\n",
       "      <td>0.968047</td>\n",
       "      <td>0.219570</td>\n",
       "      <td>0.457452</td>\n",
       "      <td>0.247248</td>\n",
       "      <td>0.247665</td>\n",
       "      <td>0.079178</td>\n",
       "      <td>164.333</td>\n",
       "      <td>0.229997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16161</th>\n",
       "      <td>0.919309</td>\n",
       "      <td>0.658150</td>\n",
       "      <td>0.217224</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.089775</td>\n",
       "      <td>0.574987</td>\n",
       "      <td>89.315</td>\n",
       "      <td>0.655736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>0.995764</td>\n",
       "      <td>0.574833</td>\n",
       "      <td>0.615376</td>\n",
       "      <td>0.925299</td>\n",
       "      <td>0.123738</td>\n",
       "      <td>0.092260</td>\n",
       "      <td>126.978</td>\n",
       "      <td>0.471027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3818 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          acousticness  danceability    energy  instrumentalness  liveness  \\\n",
       "track_id                                                                     \n",
       "36730         0.002562      0.371206  0.948498          0.938766  0.099965   \n",
       "75751         0.175495      0.684260  0.682260          0.000092  0.126889   \n",
       "14184         0.728182      0.489313  0.301333          0.873091  0.161249   \n",
       "36746         0.000028      0.338520  0.988323          0.917932  0.069609   \n",
       "27607         0.575338      0.844497  0.454838          0.780293  0.076708   \n",
       "...                ...           ...       ...               ...       ...   \n",
       "1890          0.171406      0.456081  0.680751          0.930712  0.081202   \n",
       "21521         0.179581      0.564068  0.743802          0.634654  0.117850   \n",
       "4108          0.968047      0.219570  0.457452          0.247248  0.247665   \n",
       "16161         0.919309      0.658150  0.217224          0.000731  0.089775   \n",
       "1691          0.995764      0.574833  0.615376          0.925299  0.123738   \n",
       "\n",
       "          speechiness    tempo   valence  \n",
       "track_id                                  \n",
       "36730        0.118478  120.170  0.052455  \n",
       "75751        0.038587   89.989  0.332568  \n",
       "14184        0.057750   75.044  0.614381  \n",
       "36746        0.110313  143.774  0.089863  \n",
       "27607        0.064396  130.051  0.352131  \n",
       "...               ...      ...       ...  \n",
       "1890         0.028629  107.080  0.496760  \n",
       "21521        0.036937  128.056  0.813390  \n",
       "4108         0.079178  164.333  0.229997  \n",
       "16161        0.574987   89.315  0.655736  \n",
       "1691         0.092260  126.978  0.471027  \n",
       "\n",
       "[3818 rows x 8 columns]"
      ]
     },
     "execution_count": 1505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7, stratify=y)\n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_genre_fatures_sc = scaler.fit_transform(X_train)\n",
    "X_train_sc_df = pd.DataFrame(train_genre_fatures_sc, columns = full_features)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_genre_fatures_sc = scaler.fit_transform(X_test)\n",
    "X_test_sc_df = pd.DataFrame(train_genre_fatures_sc, columns = full_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "undersampling_ratio = dict(zip(list(y_train.unique()), [1000, 637, 242, 46, 169]))\n",
    "undersampling_ratio\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "sampler=RandomUnderSampler(sampling_strategy=undersampling_ratio)\n",
    "Xu,yu=sampler.fit_resample(X_train_sc_df,y_train)\n",
    "\n",
    "yu.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Extra Hip Hop for Training\n",
    "extra_hip_hop_train_data = derived_genre_fatures_df[derived_genre_fatures_df.genre_top == 'Hip-Hop'][features + ['tempo']].sample(800 - 637)\n",
    "Xu = Xu.append(extra_hip_hop_train_data.drop('genre_top', axis=1))\n",
    "yu = yu.append(extra_hip_hop_train_data.genre_top.sample(800 - 637))\n",
    "\n",
    "# Extra Pop for Training\n",
    "extra_pop_train_data = derived_genre_fatures_df[derived_genre_fatures_df.genre_top == 'Pop'][features + ['tempo']].sample(600 - 242)\n",
    "Xu = Xu.append(extra_pop_train_data.drop('genre_top', axis=1))\n",
    "yu = yu.append(extra_pop_train_data.genre_top)\n",
    "\n",
    "# Extra Jazz for Training\n",
    "extra_jazz_train_data = derived_genre_fatures_df[derived_genre_fatures_df.genre_top == 'Jazz'][features + ['tempo']].sample(400 - 169)\n",
    "Xu = Xu.append(extra_jazz_train_data.drop('genre_top', axis=1))\n",
    "yu = yu.append(extra_jazz_train_data.genre_top)\n",
    "               \n",
    "# Extra Blues for Training\n",
    "extra_blues_train_data = derived_genre_fatures_df[derived_genre_fatures_df.genre_top == 'Blues'][features + ['tempo']].sample(170 - 46)\n",
    "Xu = Xu.append(extra_blues_train_data.drop('genre_top', axis=1))\n",
    "yu = yu.append(extra_blues_train_data.genre_top)\n",
    "\n",
    "print(Xu.shape[0], yu.shape[0])\n",
    "\n",
    "oversampling_ratio = dict(zip(list(y_train.unique()), [1000, 900, 800, 600, 600]))\n",
    "oversampling_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "categorical_mask=(X_train.dtypes=='category').values\n",
    "sm=RandomOverSampler(sampling_strategy=oversampling_ratio)\n",
    "X_train_rs,y_train_rs=sm.fit_resample(Xu,yu)\n",
    "\n",
    "print(y_train_rs.value_counts())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "clf_RF = RandomForestClassifier(max_depth=10, random_state=7, n_estimators=500)\n",
    "clf_RF.fit(X_train_rs, y_train_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y_pred = clf_RF.predict(X_test_sc_df)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred, average=\"macro\"))    \n",
    "custom_plot_confusion_matrix(confusion_matrix(y_test, clf_RF.predict(X_test_sc_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## Mejorando con GridSearch Stratified KFold   \n",
    "model_instance = RandomForestClassifier()\n",
    "\n",
    "gridSearch_params = {'n_estimators':[500, 1000],\n",
    "          'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': [None, 3, 7, 10, 15],\n",
    "          'min_samples_split': [5, 7],\n",
    "          'class_weight':[None, 'balanced']}\n",
    "\n",
    "\n",
    "cv_Stratified_KFold = StratifiedKFold(n_splits=5, shuffle=True, random_state=77)\n",
    "\n",
    "grid_search_CV_Stratified_KFold_model_RF = GridSearchCV(model_instance, gridSearch_params, n_jobs=-1, cv = cv_Stratified_KFold)\n",
    "grid_search_CV_Stratified_KFold_model_RF.fit(X_train_rs, y_train_rs)\n",
    "\n",
    "scores_Stratified_KFold = cross_val_score(model_instance, X_train_rs, y_train_rs, cv=cv_Stratified_KFold, n_jobs=-1)\n",
    "mean_score_grid_search_CV_Stratified_KFold_model = scores_Stratified_KFold.mean()\n",
    "std_score_grid_search_CV_Stratified_KFold_model = scores_Stratified_KFold.std()    \n",
    "\n",
    "#score_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model_RF.best_score_\n",
    "#params_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model_RF.best_params_\n",
    "\n",
    "score_grid_search_CV_Stratified_KFold_model_test = grid_search_CV_Stratified_KFold_model_RF.score(X_test_sc_df, y_test)\n",
    "predictions_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model_RF.predict(X_test_sc_df)\n",
    "confusion_matrix_grid_search_CV_Stratified_KFold_model = metrics.confusion_matrix(y_test, predictions_grid_search_CV_Stratified_KFold_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y_pred = grid_search_CV_Stratified_KFold_model_RF.predict(X_test_sc_df)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred, average=\"macro\"))    \n",
    "custom_plot_confusion_matrix(confusion_matrix(y_test, grid_search_CV_Stratified_KFold_model_RF.predict(X_test_sc_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## Usando XG Boosting\n",
    "model_instance = XGBRFClassifier(n_estimators=1000, subsample=0.9, colsample_bynode=0.2)\n",
    "\n",
    "gridSearch_params = {'n_estimators':[500, 1000, 1500],\n",
    "                     'max_depth': [None, 3,4,5]}\n",
    "\n",
    "\n",
    "cv_Stratified_KFold = StratifiedKFold(n_splits=4, shuffle=True, random_state=77)\n",
    "\n",
    "grid_search_CV_Stratified_KFold_model = GridSearchCV(model_instance, gridSearch_params, n_jobs=-1, cv = cv_Stratified_KFold)\n",
    "grid_search_CV_Stratified_KFold_model.fit(X_train_rs, y_train_rs)\n",
    "\n",
    "scores_Stratified_KFold = cross_val_score(model_instance, X_train_rs, y_train_rs, cv=cv_Stratified_KFold, n_jobs=-1)\n",
    "mean_score_grid_search_CV_Stratified_KFold_model = scores_Stratified_KFold.mean()\n",
    "std_score_grid_search_CV_Stratified_KFold_model = scores_Stratified_KFold.std()    \n",
    "\n",
    "score_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model.best_score_\n",
    "params_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model.best_params_\n",
    "\n",
    "score_grid_search_CV_Stratified_KFold_model_test = grid_search_CV_Stratified_KFold_model.score(X_test_sc_df, y_test)\n",
    "predictions_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model.predict(X_test_sc_df)\n",
    "confusion_matrix_grid_search_CV_Stratified_KFold_model = metrics.confusion_matrix(y_test, predictions_grid_search_CV_Stratified_KFold_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y_pred = grid_search_CV_Stratified_KFold_model.predict(X_test_sc_df)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred, average=\"macro\"))    \n",
    "custom_plot_confusion_matrix(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Añadiendo información de anális de audio \n",
    "_features = [\"chroma_cens\", \"chroma_cqt\", \"chroma_stft\", \"mfcc\", \"rmse\", \"spectral_bandwidth\", \"spectral_contrast\", \"spectral_rolloff\", \"tonnetz\", \"zcr\"]\n",
    "_fields = [\"kurtosis\", \"mean\", \"std\", \"median\", \"max\", \"min\"]\n",
    "\n",
    "audio_features_df  = features_df[features_df.index.isin(list(genre_fatures_df.index) + list(derived_genre_fatures_df.index))][_features]\n",
    "audio_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Flatten features\n",
    "tracks_with_extra_audio_features_df = pd.DataFrame(index=audio_features_df.index)\n",
    "tracks_with_extra_audio_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## Initializing all needed columns with NaN\n",
    "for index, row in audio_features_df.head(1).iterrows():\n",
    "    print(index) # track id\n",
    "    for feature in _features:\n",
    "        for field in _fields:\n",
    "            i = 0\n",
    "            for k in row[feature][field]: # channel (if it is channel ?)                \n",
    "                i += 1\n",
    "                tracks_with_extra_audio_features_df[f'{feature}_{field[0:3]}_{i}'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for index, row in audio_features_df.iterrows():\n",
    "    for feature in _features:\n",
    "        for field in _fields:\n",
    "            i = 0\n",
    "            for k in row[feature][field]: # channel (if it is channel ?)                \n",
    "                i += 1\n",
    "                tracks_with_extra_audio_features_df[f'{feature}_{field[0:3]}_{i}'] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tracks_with_extra_audio_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "extra_audio_genre_df = pd.concat([genre_fatures_df, tracks_with_extra_audio_features_df[tracks_with_extra_audio_features_df.index.isin(genre_fatures_df.index)]], 1)\n",
    "\n",
    "extra_audio_derived_genre_df = pd.concat([derived_genre_fatures_df, tracks_with_extra_audio_features_df[tracks_with_extra_audio_features_df.index.isin(derived_genre_fatures_df.index)]], 1)\n",
    "\n",
    "extra_audio_genre_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X = extra_audio_genre_df.drop(['genre_top', '_genre_top', 'genres', 'genres_all', 'track_id'], axis=1)\n",
    "y = extra_audio_genre_df['genre_top']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7, stratify=y)\n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_genre_fatures_sc = scaler.fit_transform(X_train)\n",
    "X_train_sc_df = pd.DataFrame(train_genre_fatures_sc, columns = X.columns)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_genre_fatures_sc = scaler.fit_transform(X_test)\n",
    "X_test_sc_df = pd.DataFrame(train_genre_fatures_sc, columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "undersampling_ratio = dict(zip(list(y_train.unique()), [1000, 637, 242, 46, 169]))\n",
    "undersampling_ratio\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "sampler=RandomUnderSampler(sampling_strategy=undersampling_ratio)\n",
    "Xu,yu=sampler.fit_resample(X_train_sc_df,y_train)\n",
    "\n",
    "yu.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Extra Hip Hop for Training\n",
    "\n",
    "cols_to_drop = ['genre_top', 'genres', 'genres_all', 'track_id', 'genres_all_str', 'genres_str', 'derived_genre_top']\n",
    "\n",
    "extra_hip_hop_train_data = extra_audio_derived_genre_df[extra_audio_derived_genre_df.genre_top == 'Hip-Hop'].sample(800 - 637)\n",
    "Xu = Xu.append(extra_hip_hop_train_data.drop(cols_to_drop, axis=1))\n",
    "yu = yu.append(extra_hip_hop_train_data.genre_top.sample(800 - 637))\n",
    "\n",
    "# Extra Pop for Training\n",
    "extra_pop_train_data = extra_audio_derived_genre_df[extra_audio_derived_genre_df.genre_top == 'Pop'].sample(600 - 242)\n",
    "Xu = Xu.append(extra_pop_train_data.drop(cols_to_drop, axis=1))\n",
    "yu = yu.append(extra_pop_train_data.genre_top)\n",
    "\n",
    "# Extra Jazz for Training\n",
    "extra_jazz_train_data = extra_audio_derived_genre_df[extra_audio_derived_genre_df.genre_top == 'Jazz'].sample(400 - 169)\n",
    "Xu = Xu.append(extra_jazz_train_data.drop(cols_to_drop, axis=1))\n",
    "yu = yu.append(extra_jazz_train_data.genre_top)\n",
    "               \n",
    "# Extra Blues for Training\n",
    "extra_blues_train_data = extra_audio_derived_genre_df[extra_audio_derived_genre_df.genre_top == 'Blues'].sample(170 - 46)\n",
    "Xu = Xu.append(extra_blues_train_data.drop(cols_to_drop, axis=1))\n",
    "yu = yu.append(extra_blues_train_data.genre_top)\n",
    "\n",
    "print(Xu.shape[0], yu.shape[0])\n",
    "yu.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "oversampling_ratio = dict(zip(list(y_train.unique()), [1000, 900, 800, 600, 600]))\n",
    "oversampling_ratio\n",
    "\n",
    "categorical_mask=(X_train_sc_df.dtypes=='category').values\n",
    "sm=RandomOverSampler(sampling_strategy=oversampling_ratio)\n",
    "X_train_rs,y_train_rs=sm.fit_resample(Xu,yu)\n",
    "\n",
    "print(y_train_rs.value_counts())    \n",
    "X_train_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "clf_RF_extra_audio = RandomForestClassifier(max_depth=10, random_state=7, n_estimators=500)\n",
    "clf_RF_extra_audio.fit(X_train_rs, y_train_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Para Todos los casos de prueba\n",
    "\n",
    "y_pred = clf_RF_extra_audio.predict(X_test_sc_df)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred, average=\"macro\"))    \n",
    "custom_plot_confusion_matrix(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## Mejorando con GridSearch Stratified KFold   \n",
    "model_instance = RandomForestClassifier()\n",
    "\n",
    "gridSearch_params = {'n_estimators':[500, 1000],\n",
    "          'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': [None, 3, 7, 10, 15],\n",
    "          'min_samples_split': [5, 7],\n",
    "          'class_weight':[None, 'balanced']}\n",
    "\n",
    "start = time.time()\n",
    "cv_Stratified_KFold = StratifiedKFold(n_splits=5, shuffle=True, random_state=77)\n",
    "\n",
    "grid_search_CV_Stratified_KFold_model_RF_extra_audio = GridSearchCV(model_instance, gridSearch_params, n_jobs=-1, cv = cv_Stratified_KFold)\n",
    "grid_search_CV_Stratified_KFold_model_RF_extra_audio.fit(X_train_rs, y_train_rs)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")\n",
    "\n",
    "scores_Stratified_KFold = cross_val_score(model_instance, X_train_rs, y_train_rs, cv=cv_Stratified_KFold, n_jobs=-1)\n",
    "mean_score_grid_search_CV_Stratified_KFold_model = scores_Stratified_KFold.mean()\n",
    "std_score_grid_search_CV_Stratified_KFold_model = scores_Stratified_KFold.std()    \n",
    "\n",
    "#score_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model_RF.best_score_\n",
    "#params_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model_RF.best_params_\n",
    "\n",
    "score_grid_search_CV_Stratified_KFold_model_test = grid_search_CV_Stratified_KFold_model_RF_extra_audio.score(X_test_sc_df, y_test)\n",
    "predictions_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model_RF_extra_audio.predict(X_test_sc_df)\n",
    "confusion_matrix_grid_search_CV_Stratified_KFold_model = metrics.confusion_matrix(y_test, predictions_grid_search_CV_Stratified_KFold_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y_pred = grid_search_CV_Stratified_KFold_model_RF.predict(X_test_sc_df)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred, average=\"macro\"))    \n",
    "custom_plot_confusion_matrix(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## Usando XG Boosting\n",
    "model_instance = XGBRFClassifier(n_estimators=1000, subsample=0.9, colsample_bynode=0.2)\n",
    "\n",
    "gridSearch_params = {'n_estimators':[500, 1000, 1500],\n",
    "                     'max_depth': [None, 3,4,5]}\n",
    "\n",
    "start = time.time()\n",
    "cv_Stratified_KFold = StratifiedKFold(n_splits=4, shuffle=True, random_state=77)\n",
    "\n",
    "grid_search_CV_Stratified_KFold_model_extra_audio = GridSearchCV(model_instance, gridSearch_params, n_jobs=-1, cv = cv_Stratified_KFold)\n",
    "grid_search_CV_Stratified_KFold_model_extra_audio.fit(X_train_rs, y_train_rs)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")\n",
    "\n",
    "scores_Stratified_KFold = cross_val_score(model_instance, X_train_rs, y_train_rs, cv=cv_Stratified_KFold, n_jobs=-1)\n",
    "mean_score_grid_search_CV_Stratified_KFold_model = scores_Stratified_KFold.mean()\n",
    "std_score_grid_search_CV_Stratified_KFold_model = scores_Stratified_KFold.std()    \n",
    "\n",
    "score_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model_extra_audio.best_score_\n",
    "params_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model_extra_audio.best_params_\n",
    "\n",
    "score_grid_search_CV_Stratified_KFold_model_test = grid_search_CV_Stratified_KFold_model_extra_audio.score(X_test_sc_df, y_test)\n",
    "predictions_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model_extra_audio.predict(X_test_sc_df)\n",
    "confusion_matrix_grid_search_CV_Stratified_KFold_model = metrics.confusion_matrix(y_test, predictions_grid_search_CV_Stratified_KFold_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y_pred = grid_search_CV_Stratified_KFold_model.predict(X_test_sc_df)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred, average=\"macro\"))    \n",
    "custom_plot_confusion_matrix(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Aplicando Reducción de dimensionalidad (PCA)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 7, random_state=7)\n",
    "X_train_pca = pca.fit_transform(X_train_sc_df)\n",
    "X_test_pca = pca.transform(X_test_sc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(explained_variance[0:10] * 100))\n",
    "plt.xlabel('Número de Componentes')\n",
    "plt.xlabel('Varianza  explicada')\n",
    "plt.savefig('elbow_plot.png', dpi=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Undersampling \n",
    "\n",
    "undersampling_ratio = dict(zip(list(y_train.unique()), [1000, 637, 242, 46, 169]))\n",
    "undersampling_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "sampler=RandomUnderSampler(sampling_strategy=undersampling_ratio)\n",
    "Xu_pca,yu_pca=sampler.fit_resample(X_train_pca,y_train)\n",
    "\n",
    "yu_pca.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "oversampling_ratio = dict(zip(list(y_train.unique()), [1000, 800, 550, 400, 600]))\n",
    "oversampling_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "categorical_mask=(X_train_sc_df.dtypes=='category').values\n",
    "sm=RandomOverSampler(sampling_strategy=oversampling_ratio)\n",
    "X_train_rs_pca,y_train_rs_pca=sm.fit_resample(Xu_pca,yu_pca)\n",
    "\n",
    "print(y_train_rs.value_counts())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y_test.value_counts()\n",
    "\n",
    "X_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "clf_RF_pca = RandomForestClassifier(max_depth=20, random_state=7, n_estimators=1000)\n",
    "clf_RF_pca.fit(X_train_rs_pca, y_train_rs_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y_pred = clf_RF_pca.predict(X_test_pca)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred, average=\"macro\"))    \n",
    "custom_plot_confusion_matrix(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## Usando XG Boosting\n",
    "model_instance = XGBRFClassifier(subsample=0.9, colsample_bynode=0.2, eval_metric=[\"error\", \"logloss\"])\n",
    "\n",
    "gridSearch_params = {'n_estimators':[50, 100, 300],\n",
    "                     'max_depth': [None, 3,4,5],\n",
    "                     'learning_rate': [0.01, 0.1]}\n",
    "\n",
    "start = time.time()\n",
    "cv_Stratified_KFold = StratifiedKFold(n_splits=3, shuffle=True, random_state=77)\n",
    "\n",
    "grid_search_CV_Stratified_KFold_model_extra_audio_pca = GridSearchCV(model_instance, gridSearch_params, n_jobs=-1, cv = cv_Stratified_KFold)\n",
    "grid_search_CV_Stratified_KFold_model_extra_audio_pca.fit(X_train_rs_pca, y_train_rs_pca)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")\n",
    "\n",
    "scores_Stratified_KFold = cross_val_score(model_instance, X_train_rs, y_train_rs, cv=cv_Stratified_KFold, n_jobs=-1)\n",
    "mean_score_grid_search_CV_Stratified_KFold_model = scores_Stratified_KFold.mean()\n",
    "std_score_grid_search_CV_Stratified_KFold_model = scores_Stratified_KFold.std()    \n",
    "\n",
    "score_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model_extra_audio_pca.best_score_\n",
    "params_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model_extra_audio_pca.best_params_\n",
    "\n",
    "score_grid_search_CV_Stratified_KFold_model_test = grid_search_CV_Stratified_KFold_model_extra_audio_pca.score(X_test_pca, y_test)\n",
    "predictions_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model_extra_audio_pca.predict(X_test_pca)\n",
    "confusion_matrix_grid_search_CV_Stratified_KFold_model = metrics.confusion_matrix(y_test, predictions_grid_search_CV_Stratified_KFold_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y_pred = grid_search_CV_Stratified_KFold_model_extra_audio_pca.predict(X_test_pca)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred, average=\"macro\"))    \n",
    "custom_plot_confusion_matrix(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## Usando XG Boosting - Cambiando Métrica\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model_instance = XGBRFClassifier(eval_metric=[\"error\", \"logloss\"])\n",
    "\n",
    "gridSearch_params = {\n",
    "                     'n_estimators': [5, 50, 100, 500, 1000],\n",
    "                     'max_depth': [3, 4],\n",
    "                     'learning_rate': [0.01, 0.1],\n",
    "                     'min_child_weight': [1, 5, 10],\n",
    "                     'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "                     'subsample': [0.6, 0.8, 1.0],\n",
    "                     'colsample_bytree': [0.3, 0.6, 0.8],\n",
    "                     'colsample_bynode': [0.2, 0.4, 0.6]\n",
    "                    }\n",
    "\n",
    "start = time.time()\n",
    "cv_Stratified_KFold = StratifiedKFold(n_splits=3, shuffle=True, random_state=105)\n",
    "\n",
    "grid_search_CV_Stratified_KFold_model_extra_audio_pca_ht = GridSearchCV(model_instance, gridSearch_params, n_jobs=-1, cv = cv_Stratified_KFold, verbose=3)\n",
    "grid_search_CV_Stratified_KFold_model_extra_audio_pca_ht.fit(X_train_rs_pca, y_train_rs_pca)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")\n",
    "\n",
    "scores_Stratified_KFold = cross_val_score(model_instance, X_train_rs, y_train_rs, cv=cv_Stratified_KFold, n_jobs=-1)\n",
    "mean_score_grid_search_CV_Stratified_KFold_model = scores_Stratified_KFold.mean()\n",
    "std_score_grid_search_CV_Stratified_KFold_model = scores_Stratified_KFold.std()    \n",
    "\n",
    "score_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model_extra_audio_pca_ht.best_score_\n",
    "params_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model_extra_audio_pca_ht.best_params_\n",
    "\n",
    "score_grid_search_CV_Stratified_KFold_model_test = grid_search_CV_Stratified_KFold_model_extra_audio_pca_ht.score(X_test_pca, y_test)\n",
    "predictions_grid_search_CV_Stratified_KFold_model = grid_search_CV_Stratified_KFold_model_extra_audio_pca_ht.predict(X_test_pca)\n",
    "confusion_matrix_grid_search_CV_Stratified_KFold_model = metrics.confusion_matrix(y_test, predictions_grid_search_CV_Stratified_KFold_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y_pred = grid_search_CV_Stratified_KFold_model_extra_audio_pca_ht.predict(X_test_pca)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred, average=\"macro\"))    \n",
    "custom_plot_confusion_matrix(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
